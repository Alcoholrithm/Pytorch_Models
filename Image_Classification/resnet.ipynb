{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "from resnet import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ResNet([3, 3, 3], 10).to('cuda') # resnet20\n",
    "model = ResNet([5, 5, 5], 10).to('cuda') # resnet32\n",
    "#model = ResNet([7, 7, 7], 10) # resnet44\n",
    "#model = ResNet([9, 9, 9], 10) # resnet56\n",
    "#model = ResNet([18, 18, 18], 10) # resnet110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
      "              ReLU-6           [-1, 16, 32, 32]               0\n",
      "            Conv2d-7           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
      "              ReLU-9           [-1, 16, 32, 32]               0\n",
      "    ResidualBlock-10           [-1, 16, 32, 32]               0\n",
      "           Conv2d-11           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-12           [-1, 16, 32, 32]              32\n",
      "             ReLU-13           [-1, 16, 32, 32]               0\n",
      "           Conv2d-14           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-15           [-1, 16, 32, 32]              32\n",
      "             ReLU-16           [-1, 16, 32, 32]               0\n",
      "    ResidualBlock-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
      "             ReLU-20           [-1, 16, 32, 32]               0\n",
      "           Conv2d-21           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-22           [-1, 16, 32, 32]              32\n",
      "             ReLU-23           [-1, 16, 32, 32]               0\n",
      "    ResidualBlock-24           [-1, 16, 32, 32]               0\n",
      "           Conv2d-25           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-26           [-1, 16, 32, 32]              32\n",
      "             ReLU-27           [-1, 16, 32, 32]               0\n",
      "           Conv2d-28           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-29           [-1, 16, 32, 32]              32\n",
      "             ReLU-30           [-1, 16, 32, 32]               0\n",
      "    ResidualBlock-31           [-1, 16, 32, 32]               0\n",
      "           Conv2d-32           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-33           [-1, 16, 32, 32]              32\n",
      "             ReLU-34           [-1, 16, 32, 32]               0\n",
      "           Conv2d-35           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-36           [-1, 16, 32, 32]              32\n",
      "             ReLU-37           [-1, 16, 32, 32]               0\n",
      "    ResidualBlock-38           [-1, 16, 32, 32]               0\n",
      "           Conv2d-39           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-40           [-1, 32, 16, 16]              64\n",
      "             ReLU-41           [-1, 32, 16, 16]               0\n",
      "           Conv2d-42           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
      "        MaxPool2d-44           [-1, 32, 16, 16]               0\n",
      " IdentityShortcut-45           [-1, 32, 16, 16]               0\n",
      "             ReLU-46           [-1, 32, 16, 16]               0\n",
      "    ResidualBlock-47           [-1, 32, 16, 16]               0\n",
      "           Conv2d-48           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-49           [-1, 32, 16, 16]              64\n",
      "             ReLU-50           [-1, 32, 16, 16]               0\n",
      "           Conv2d-51           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-52           [-1, 32, 16, 16]              64\n",
      "             ReLU-53           [-1, 32, 16, 16]               0\n",
      "    ResidualBlock-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-56           [-1, 32, 16, 16]              64\n",
      "             ReLU-57           [-1, 32, 16, 16]               0\n",
      "           Conv2d-58           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
      "             ReLU-60           [-1, 32, 16, 16]               0\n",
      "    ResidualBlock-61           [-1, 32, 16, 16]               0\n",
      "           Conv2d-62           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-63           [-1, 32, 16, 16]              64\n",
      "             ReLU-64           [-1, 32, 16, 16]               0\n",
      "           Conv2d-65           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-66           [-1, 32, 16, 16]              64\n",
      "             ReLU-67           [-1, 32, 16, 16]               0\n",
      "    ResidualBlock-68           [-1, 32, 16, 16]               0\n",
      "           Conv2d-69           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-70           [-1, 32, 16, 16]              64\n",
      "             ReLU-71           [-1, 32, 16, 16]               0\n",
      "           Conv2d-72           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-73           [-1, 32, 16, 16]              64\n",
      "             ReLU-74           [-1, 32, 16, 16]               0\n",
      "    ResidualBlock-75           [-1, 32, 16, 16]               0\n",
      "           Conv2d-76             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-77             [-1, 64, 8, 8]             128\n",
      "             ReLU-78             [-1, 64, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      "        MaxPool2d-81             [-1, 64, 8, 8]               0\n",
      " IdentityShortcut-82             [-1, 64, 8, 8]               0\n",
      "             ReLU-83             [-1, 64, 8, 8]               0\n",
      "    ResidualBlock-84             [-1, 64, 8, 8]               0\n",
      "           Conv2d-85             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-86             [-1, 64, 8, 8]             128\n",
      "             ReLU-87             [-1, 64, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      "             ReLU-90             [-1, 64, 8, 8]               0\n",
      "    ResidualBlock-91             [-1, 64, 8, 8]               0\n",
      "           Conv2d-92             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-93             [-1, 64, 8, 8]             128\n",
      "             ReLU-94             [-1, 64, 8, 8]               0\n",
      "           Conv2d-95             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-96             [-1, 64, 8, 8]             128\n",
      "             ReLU-97             [-1, 64, 8, 8]               0\n",
      "    ResidualBlock-98             [-1, 64, 8, 8]               0\n",
      "           Conv2d-99             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-100             [-1, 64, 8, 8]             128\n",
      "            ReLU-101             [-1, 64, 8, 8]               0\n",
      "          Conv2d-102             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-103             [-1, 64, 8, 8]             128\n",
      "            ReLU-104             [-1, 64, 8, 8]               0\n",
      "   ResidualBlock-105             [-1, 64, 8, 8]               0\n",
      "          Conv2d-106             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-107             [-1, 64, 8, 8]             128\n",
      "            ReLU-108             [-1, 64, 8, 8]               0\n",
      "          Conv2d-109             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-110             [-1, 64, 8, 8]             128\n",
      "            ReLU-111             [-1, 64, 8, 8]               0\n",
      "   ResidualBlock-112             [-1, 64, 8, 8]               0\n",
      "       AvgPool2d-113             [-1, 64, 1, 1]               0\n",
      "         Flatten-114                   [-1, 64]               0\n",
      "          Linear-115                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 464,154\n",
      "Trainable params: 464,154\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 8.22\n",
      "Params size (MB): 1.77\n",
      "Estimated Total Size (MB): 10.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_cifar10 = CIFAR10(root = '../datasets/cifar10', train=True, download=True)\n",
    "val_cifar10 = CIFAR10(root = '../datasets/cifar10', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_cifar10.data.mean(axis=(0,1,2)) / 255\n",
    "train_std = train_cifar10.data.std(axis=(0,1,2)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                        #transforms.Resize(224),\n",
    "                                        transforms.RandomCrop(32, padding=4),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(train_mean, train_std),                                      \n",
    "                                        ])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        #transforms.Resize(224),\n",
    "                                        transforms.Normalize(train_mean, train_std)\n",
    "                                        ])\n",
    "\n",
    "train_cifar10.transform = train_transforms\n",
    "val_cifar10.transform = train_transforms\n",
    "\n",
    "train_dl = DataLoader(train_cifar10, batch_size=256, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_cifar10, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_correct(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [03:00<26:43, 17.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss = 0.51 |  train_acc = 82.58 | val_loss = 0.65 | val_acc = 77.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [05:59<24:09, 18.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train_loss = 0.34 |  train_acc = 88.31 | val_loss = 0.52 | val_acc = 82.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [08:59<20:49, 17.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | train_loss = 0.26 |  train_acc = 90.94 | val_loss = 0.47 | val_acc = 84.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [11:58<17:50, 17.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | train_loss = 0.22 |  train_acc = 92.12 | val_loss = 0.51 | val_acc = 84.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [14:57<14:52, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | train_loss = 0.19 |  train_acc = 93.38 | val_loss = 0.50 | val_acc = 84.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [17:56<11:57, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | train_loss = 0.18 |  train_acc = 93.67 | val_loss = 0.44 | val_acc = 86.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [20:55<08:55, 17.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | train_loss = 0.17 |  train_acc = 93.97 | val_loss = 0.43 | val_acc = 86.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [23:54<05:57, 17.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | train_loss = 0.15 |  train_acc = 94.58 | val_loss = 0.57 | val_acc = 82.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [26:53<02:58, 17.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | train_loss = 0.14 |  train_acc = 94.94 | val_loss = 0.49 | val_acc = 85.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [29:51<00:00, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | train_loss = 0.14 |  train_acc = 94.98 | val_loss = 0.45 | val_acc = 87.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('resnet_logs')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "epochs = 100\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "decay_epoch = [32000, 48000]\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "best_model = None\n",
    "best_accs = -1\n",
    "for _ in tqdm(range(epochs)):\n",
    "    global_loss = 0\n",
    "    corrects = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dl):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        global_loss = global_loss + loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        corrects += count_correct(output, target)\n",
    "\n",
    "    train_losses.append(global_loss / (batch_idx + 1))\n",
    "    train_accs.append(corrects / len(train_cifar10) * 100)\n",
    "    \n",
    "    model.eval()\n",
    "    corrects = 0\n",
    "    global_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(val_dl):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            loss = loss_func(output, target)\n",
    "            global_loss = global_loss + loss.item()\n",
    "            corrects += count_correct(output, target)\n",
    "\n",
    "    val_losses.append(global_loss / (batch_idx + 1))\n",
    "    val_accs.append(corrects / len(val_cifar10) * 100)\n",
    "    \n",
    "    writer.add_scalar('resnet_log/train_error', 100 - train_accs[-1], _ + 1)\n",
    "    writer.add_scalar('resnet_log/validation_error', 100 - val_accs[-1], _ + 1)\n",
    "    \n",
    "    if (_ + 1) % 10 == 0:\n",
    "        print(\"Epoch %d | train_loss = %.2f |  train_acc = %.2f | val_loss = %.2f | val_acc = %.2f\" % (_ + 1, train_losses[-1], train_accs[-1], val_losses[-1], val_accs[-1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e229920edd51aea19e88d6f5beb6077fb3a4e96681a811b0949e41c8aa8fa312"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('oscar': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
